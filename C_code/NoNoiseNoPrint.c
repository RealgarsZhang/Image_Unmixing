#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

#include "magma.h"
#include "magma_lapack.h"
#include "cublas_v2.h"


#include"NoNoiseNoPrint.h"

double tanh(double x){
   return (exp(x)-exp(-x))/(exp(x)+exp(-x));
 
}

/*******************************************************
    Description: my_dgemm takes three CPU matrices as input and performs
 the computation with magma_dgemm().
    Note: 1. Essentially all matrices are passed by reference.
          2. This function should be called in magma context. 
************************************************************/
void my_dgemm(MATRIX A, MATRIX B, MATRIX C, 
              double alpha, double beta,
	      magma_trans_t A_tran,
	      magma_trans_t B_tran){
    MATRIX d_A, d_B, d_C;
    magma_int_t err;

    d_A.row = A.row;
    d_A.col = A.col;
    err = magma_dmalloc( &(d_A.data),     d_A.row * d_A.col );	
    
    d_B.row = B.row;
    d_B.col = B.col;
    err = magma_dmalloc( &(d_B.data),     d_B.row * d_B.col );

    d_C.row = C.row;
    d_C.col = C.col;
    err = magma_dmalloc( &(d_C.data),     d_C.row * d_C.col ); 
        
	  
	magma_dsetmatrix( A.row, A.col, A.data,
	                  A.row, d_A.data, d_A.row);

	magma_dsetmatrix( B.row, B.col, B.data,
	                  B.row, d_B.data, d_B.row);
	
	magma_dsetmatrix( C.row, C.col, C.data,
	                  C.row, d_C.data, d_C.row);

        magma_dgemm(    A_tran, B_tran,
	                d_A.row, d_B.col, d_A.col,
		        alpha, 
		        d_A.data,     d_A.row, 
		        d_B.data,     d_B.row,
		        beta,
                        d_C.data,     d_C.row);


        magma_dgetmatrix (C.row, C.col, d_C.data, C.row, 
	                  C.data, C.row);
        
	magma_free(d_A.data);
	magma_free(d_B.data);
	magma_free(d_C.data);
                    

}
/*********************************************************
 * my_sum() takes the required inputnd performs cublasDaxpy
   to comput C = alpha*A+B
 * NOTE: The cublas context will be set in the function
 * ********************************************************/
void my_sum ( MATRIX A, MATRIX B, MATRIX C, double alpha ){
    MATRIX d_A, d_B; 
    cublasStatus_t stat;
    cublasHandle_t handle;
    unsigned int n;
    int err;

    d_A.row = A.row;
    d_A.col = A.col;
    err = cudaMalloc( (void**)&(d_A.data), sizeof(double)*d_A.row * d_A.col );	
    
    d_B.row = B.row;
    d_B.col = B.col;
    err = cudaMalloc( (void**)&(d_B.data), sizeof(double)*d_B.row * d_B.col );
    
    stat = cublasCreate( &handle );
    n = A.row * A.col;
    stat = cublasSetVector( n, sizeof(double), A.data, 1, d_A.data, 1);

    stat = cublasSetVector( n, sizeof(double), B.data, 1, d_B.data, 1);



    stat = cublasDaxpy( handle, n, &alpha, d_A.data, 1, d_B.data, 1 );
    // Here d_B stores the result  
    
    stat = cublasGetVector( n, sizeof(double), d_B.data, 1, C.data, 1);
    
    stat = cublasDestroy(handle);

	cudaFree(d_A.data);
	cudaFree(d_B.data);
                    

}   



/**************************************************
  Description: readinExamples() reads in the examples 
generated by matlab.For each set of training examles,
both the examples image and the coeffcients for the 
three basic modes are provided.
  Return value: 0 if some error, 1 if everything ok.

  NOTE: You should pass the address of the matrix
        Don't malloc space of the matrix! This is 
	done in this function!!!

	All arguments are allocated and NOT freed.
************************************************/
int readinExamples(MATRIX* ptr_coefMatrix_train,
                    MATRIX* ptr_coefMatrix_cv,
                    MATRIX* ptr_coefMatrix_test,
                    MATRIX* ptr_examples_train,
                    MATRIX* ptr_examples_cv,
                    MATRIX* ptr_examples_test){
    FILE* fileInput;
    magma_int_t row,col;
    magma_int_t temp_size;
    magma_int_t i;
    magma_int_t err;
    double temp;
    
    
    //readin coefMatrix_train
    fileInput = fopen("./examples/coefMatrix_train","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_coefMatrix_train->row = row;
    ptr_coefMatrix_train->col = col;
    err = magma_dmalloc_cpu(&(ptr_coefMatrix_train->data), row*col);
    
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
	fscanf( fileInput, "%lf", &temp );
        ptr_coefMatrix_train->data[i] = temp;
        i++;
    }
    fclose( fileInput );
    
    //read coefMatrix_cv
    fileInput = fopen("./examples/coefMatrix_cv","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_coefMatrix_cv->row = row;
    ptr_coefMatrix_cv->col = col;
   // ptr_coefMatrix_cv->data= (double*)malloc(sizeof(double)*row*col);
    err = magma_dmalloc_cpu(&(ptr_coefMatrix_cv->data), row*col);
    
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
	fscanf( fileInput, "%lf", &temp );
        ptr_coefMatrix_cv->data[i] = temp;
        i++;
    }
    fclose( fileInput );
    
    //read in coefMatrix_test
    fileInput = fopen("./examples/coefMatrix_test","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_coefMatrix_test->row = row;
    ptr_coefMatrix_test->col = col;
    //ptr_coefMatrix_test->data= (double*)malloc(sizeof(double)*row*col);
    err = magma_dmalloc_cpu(&(ptr_coefMatrix_test->data), row*col);
    
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
	fscanf( fileInput, "%lf", &temp );
        ptr_coefMatrix_test->data[i] = temp;
        i++;
    }
    fclose( fileInput );
 
 
    fileInput = fopen("./examples/examples_train","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_train->row = row;
    ptr_examples_train->col = col;
    //ptr_examples_train->data= (double*)malloc(sizeof(double)*tempsize);
    err = magma_dmalloc_cpu(&(ptr_examples_train->data), row*col);
    
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
        fscanf( fileInput, "%lf", &temp );
        ptr_examples_train->data[i] = temp;
        i++;
    }
    fclose( fileInput );
 
    fileInput = fopen("./examples/examples_cv","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_cv->row = row;
    ptr_examples_cv->col = col;
  //  ptr_examples_cv->data= (double*)malloc(sizeof(double)*tempsize);
    err = magma_dmalloc_cpu(&(ptr_examples_cv->data), row*col);

    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
        fscanf( fileInput, "%lf", &temp );
        ptr_examples_cv->data[i] = temp;
        i++;
    }
    fclose( fileInput );

    fileInput = fopen("./examples/examples_test","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_test->row = row;
    ptr_examples_test->col = col;
  //  ptr_examples_test->data= (double*)malloc(sizeof(double)*tempsize);
    err = magma_dmalloc_cpu(&(ptr_examples_test->data), row*col);

    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
	fscanf( fileInput, "%lf", &temp );
        ptr_examples_test->data[i] = temp;
        i++;
    }
    fclose( fileInput );
    return (1);
}
/***************************************************
    Description: padOne() add a row where all entries are
  1 to the top of a matrix A. Return a MATRIX struct
    NOTE : malloc() is called here,to allocate space for the 
  new matrix.
           The returned matrix is allocated and NOT freed.
****************************************************/
MATRIX padOne(MATRIX A){
    MATRIX returnMatrix;
    int i,j,mallocSize;
    magma_int_t err;

    returnMatrix.col = A.col;
    returnMatrix.row = A.row + 1;
    mallocSize = returnMatrix.col * returnMatrix.row;
    //returnMatrix.data= (double*)malloc(sizeof(double)*returnMatrix.col*returnMatrix.row);
    err = magma_dmalloc_cpu(&(returnMatrix.data), mallocSize);

    for( i=0; i<A.col; i++){
        returnMatrix.data[i*returnMatrix.row] = 1; //pad 1 here
    }
    for( i=1; i<returnMatrix.row; i++)
        for( j=0; j<returnMatrix.col; j++){
	    returnMatrix.data[j*returnMatrix.row+i]=A.data[j*A.row+i-1];
	    //Copies main part of A.Potentially slow!!!
	}
    return returnMatrix;	   
}
/***************************************************************
 * the remove_top_row removes the top row of a matrix. A pointer to this matrix    is passed to the function.Principally, this function is only used in trimming the delta in backpropogation.
 ***************************************************************/

void remove_top_row(MATRIX* ptr_delta){
    
    magma_int_t mallocSize; 
    double* tempArray, *temp;
    int i, j, k1, k2;
    mallocSize = (ptr_delta->row - 1) * ptr_delta->col;
    magma_dmalloc_cpu( &tempArray, mallocSize );
    int k = 0;
    for( j=0; j<ptr_delta->col; j++)	
        for( i=1; i<ptr_delta->row; i++){
           k1 = j * ptr_delta->row + i;
	   k2 = j * (ptr_delta->row-1) + i - 1;
	   tempArray[k2] = ptr_delta->data[k1];
    } 
    temp = ptr_delta->data;
    ptr_delta->data = tempArray;
    free(temp);
    ptr_delta->row -= 1;
}
/**************************************************
 *     Description: costFunction computes the value of the cost function,
 *   as well as the gradient. The return value will be the value and the
 *   argument grad will store the gradient, which is unrolled according to 
 *   the "Theta(:)" in matlab.
 *     NOTE : This function will NOT malloc for grad !
 *     ****************************************************/
double costFunction ( double* grad,
                      double* nn_params,
                      const int input_layer_size,
                      const int hidden_layer_size,
                      const int num_labels,
                      const int NUM_HIDDEN_LAYERS,
                      const MATRIX X,const MATRIX Y,
                      const double lambda){
    double J = 0;       // The value of the cost function will be stored in J.
    MATRIX* Theta, *Theta_grad;   // Theta will be a MATRIX array storing all nn_parameter   
    int currentProg = 0;
    int i = 0;
    int k = 0, index;
    int j = 0;
    int jStart, jEnd;
    int m;
    int ii,jj;
    int mallocSize;
    magma_int_t err;
    MATRIX *a, *delta;
    MATRIX d_temp, d_Theta, d_a, temp;
    double correction;
    Theta      = ( MATRIX* )malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS+1) );
    Theta_grad = ( MATRIX* )malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS+1) );
    
    Theta[0].data = & nn_params[0];
    Theta[0].row  = hidden_layer_size;
    Theta[0].col  = input_layer_size + 1;
    
    Theta_grad[0].data = & grad[0];
    Theta_grad[0].row  = hidden_layer_size;
    Theta_grad[0].col  = input_layer_size + 1;

    currentProg   = hidden_layer_size * (input_layer_size + 1) - 1; 
    // currentProg is the max index of current Theta.

    for ( i = 1; i <= NUM_HIDDEN_LAYERS-1; i++ ){
        Theta[i].data = & nn_params[currentProg+1];
	Theta[i].row  = hidden_layer_size;
 	Theta[i].col  = hidden_layer_size + 1;
        
	Theta_grad[i].data = & grad[currentProg+1];
	Theta_grad[i].row  = hidden_layer_size;
 	Theta_grad[i].col  = hidden_layer_size + 1;
       
        currentProg  += hidden_layer_size * (hidden_layer_size + 1);
    } 
    Theta[NUM_HIDDEN_LAYERS].data = & nn_params[currentProg+1];
    Theta[NUM_HIDDEN_LAYERS].row  = num_labels;
    Theta[NUM_HIDDEN_LAYERS].col  = hidden_layer_size + 1;

    Theta_grad[NUM_HIDDEN_LAYERS].data = & grad[currentProg+1];
    Theta_grad[NUM_HIDDEN_LAYERS].row  = num_labels;
    Theta_grad[NUM_HIDDEN_LAYERS].col  = hidden_layer_size + 1;


    m = X.col;
    
    /* a=[ones(1,m)];
       z=a;
       for kk=2:NUM_HIDDEN_LAYERS+1
          z{kk}=Theta{kk-1}*a{kk-1};
	  a{kk}=tanh(z{kk});
	  a{kk}=[ones(1,m);a{kk}];
   	end
    */
    a = (MATRIX*)malloc( sizeof(MATRIX)* (NUM_HIDDEN_LAYERS + 2) );
    
    a[0] = padOne( X );
    
    for( i=1; i<=NUM_HIDDEN_LAYERS; i++){
        d_a.row = a[i-1].row;
	d_a.col = a[i-1].col;
        err = magma_dmalloc( &(d_a.data),     d_a.row*d_a.col );	
        
	d_Theta.row = Theta[i-1].row;
	d_Theta.col = Theta[i-1].col;
	err = magma_dmalloc( &(d_Theta.data), d_Theta.row*d_Theta.col);

        d_temp.row = d_Theta.row;
	d_temp.col = d_a.col;
	err = magma_dmalloc( &(d_temp.data),  d_temp.row*d_temp.col); 
        
	temp.row = d_Theta.row;
	temp.col = d_a.col;
	err = magma_dmalloc_cpu( &(temp.data),  temp.row*temp.col); 


	magma_dsetmatrix( a[i-1].row, a[i-1].col, a[i-1].data,
	                  a[i-1].row, d_a.data, d_a.row);

	magma_dsetmatrix( Theta[i-1].row, Theta[i-1].col, Theta[i-1].data,
	                  Theta[i-1].row, d_Theta.data, d_Theta.row);
        // Principally, I should set some value to d_temp so that inside is notrrubbish
        magma_dgemm(MagmaNoTrans, MagmaNoTrans,
	            d_Theta.row, d_a.col, d_Theta.col,
		    1.0, 
		    d_Theta.data, d_Theta.row, 
		    d_a.data,     d_a.row,
		    0.0,
                    d_temp.data,  d_temp.row);
        
        magma_dgetmatrix(temp.row, temp.col, d_temp.data, temp.row, 
	                 temp.data, temp.row);
 
        magma_free(d_a.data);
	magma_free(d_Theta.data);
        magma_free(d_temp.data);
        //my_dgemm( Theta[i-1].data, a[i-1].data, temp.data , 1.0, o.0);
	for( ii=0; ii<temp.row*temp.col; ii++){
	    temp.data[ii] = tanh( temp.data[ii] );
	}
	
	a[i] = padOne( temp );


        free(temp.data);
     }
    a[NUM_HIDDEN_LAYERS+1].row = Theta[NUM_HIDDEN_LAYERS].row;
    a[NUM_HIDDEN_LAYERS+1].col = a[NUM_HIDDEN_LAYERS].col; 
    err = magma_dmalloc_cpu( &( a[NUM_HIDDEN_LAYERS+1].data ),
                    a[NUM_HIDDEN_LAYERS+1].col*a[NUM_HIDDEN_LAYERS+1].row );    
    my_dgemm( Theta[NUM_HIDDEN_LAYERS], 
              a[NUM_HIDDEN_LAYERS], 
              a[NUM_HIDDEN_LAYERS+1], 
              1.0, 0.0,
	      MagmaNoTrans,
	      MagmaNoTrans);
    
    //my_sum ( Y , a[NUM_HIDDEN_LAYERS+1], diff, -1.0 );
    for (i=0; i<Y.col*Y.row; i++){
       J+=(a[NUM_HIDDEN_LAYERS+1].data[i] - Y.data[i])
          *(a[NUM_HIDDEN_LAYERS+1].data[i] - Y.data[i]);
    }
    J /= 2;
    
    //regularization
    correction = 0;
    for( i=0; i<NUM_HIDDEN_LAYERS+1; i++ ){
        jStart = Theta[i].col;
	jEnd   = Theta[i].col * Theta[i].row;
	for ( j=jStart; j<jEnd; j++){
            correction += Theta[i].data[j]*Theta[i].data[j];  	   
	}
    }
    correction *= lambda/2;
    J += correction;
    delta = (MATRIX*)malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS + 2) );   
    
    //delta{end}=output-Y;
    //delta[NUM_HIDDEN_LAYERS+1].data = (double*) malloc 
    //                                          (sizeof(double)*Y.row*Y.col);
    magma_dmalloc_cpu( &(delta[NUM_HIDDEN_LAYERS+1].data), Y.row*Y.col );

    for( i=0; i<Y.col*Y.row; i++){
        delta[NUM_HIDDEN_LAYERS+1].data[i]= 
	    a[NUM_HIDDEN_LAYERS+1].data[i]-Y.data[i];
    }
    delta[NUM_HIDDEN_LAYERS+1].row = Y.row; 
    delta[NUM_HIDDEN_LAYERS+1].col = Y.col;
    
    
    my_dgemm( delta[NUM_HIDDEN_LAYERS+1], 
                  a[NUM_HIDDEN_LAYERS+1],
		  Theta_grad[NUM_HIDDEN_LAYERS],
		  1.0,
		  0.0,
		  MagmaNoTrans,
		  MagmaTrans);
 
    for( i=1; i<=NUM_HIDDEN_LAYERS; i++ ){
        k = NUM_HIDDEN_LAYERS - i;
	delta[k+1].col = Y.col;
	delta[k+1].row = Theta[k+1].col;
        mallocSize = delta[k+1].col * delta[k+1].row;
       	//delta[k+1].data = (double*) malloc(sizeof(double)*mallocSize);
        magma_dmalloc_cpu( &(delta[k+1].data), mallocSize );  
	my_dgemm( Theta[k+1],
	          delta[k+2],
		  delta[k+1],
		  1.0,
		  0.0,
		  MagmaTrans,
		  MagmaNoTrans );
        
	for( ii=0; ii<mallocSize; ii++){
	    delta[k+1].data[ii] = delta[k+1].data[ii] * 
	    (1 - a[k+1].data[ii]*a[k+1].data[ii]); //tanh'
	}
        
	remove_top_row(&delta[k+1]);
	
	my_dgemm( delta[k+1],
	          a[k],
		  Theta_grad[k],
		  1.0,
		  0.0,
		  MagmaNoTrans,
		  MagmaTrans );
    // regularization term.              
	for( jj=1; j<Theta[k].col; jj++)	
            for( ii=0; i<Theta[k].row; ii++){
                index = ii + jj*Theta[k].row;	         
                Theta_grad[k].data[index] += lambda * Theta[k].data[index];
            }  
 

    } 
     
 // free  everything    
    for( i=0; i<NUM_HIDDEN_LAYERS+2; i++){
        free(a[i].data);
    } 
    for( i=1; i<NUM_HIDDEN_LAYERS+2; i++){
        free(delta[i].data);
    }
    free(Theta);
    free(Theta_grad);
    free(delta);
    free(a);
    return J;
}
