#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

#include "mkl.h"
#include "mkl_lapacke.h"

#include"NoNoiseNoPrintCPU.h"

double tanh(double x){
    return (exp(x)-exp(-x))/(exp(x)+exp(-x));
 
}

double random_generate(double min, double max){
    double returnValue;
    returnValue = (double)rand()/(double)RAND_MAX;
    returnValue = min + (max-min)* returnValue;
    return returnValue;   

}
/*******************************************************
    Description: my_dgemm takes three CPU matrices as input and performs
 the computation with magma_dgemm().
    Note: 1. Essentially all matrices are passed by reference.
          2. This function should be called in magma context. 
************************************************************/
void my_dgemm(MATRIX A, MATRIX B, MATRIX C, 
              double alpha, double beta,
              CBLAS_TRANSPOSE A_tran,
	      CBLAS_TRANSPOSE B_tran){
       int K;
       if ( A_tran == CblasNoTrans ){
           K = A.col;
       }else{
           K = A.row;
       }
       cblas_dgemm(     CblasColMajor,
                        A_tran, B_tran,
	                C.row, C.col, K,
		        alpha, 
		        A.data,     A.row, 
		        B.data,     B.row,
		        beta,
                        C.data,     C.row);

                   
}

/**************************************************
  Description: readinExamples() reads in the examples 
generated by matlab.For each set of training examles,
both the examples image and the coeffcients for the 
three basic modes are provided.
  Return value: 0 if some error, 1 if everything ok.

  NOTE: You should pass the address of the matrix
        Don't malloc space of the matrix! This is 
	done in this function!!!

	All arguments are allocated and NOT freed.
************************************************/
int readinExamples(MATRIX* ptr_coefMatrix_train,
                    MATRIX* ptr_coefMatrix_cv,
                    MATRIX* ptr_coefMatrix_test,
                    MATRIX* ptr_examples_train,
                    MATRIX* ptr_examples_cv,
                    MATRIX* ptr_examples_test){
    FILE* fileInput;
    int row,col;
    int temp_size;
    int i;
    int err;
    double temp;
    
    
 
   //readin coefMatrix_train
    fileInput = fopen("./examples1000/coefMatrix_train","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }
    
    fscanf(fileInput, "%d %d", &row, &col);
    //printf("row:%d col:%d\n", row, col);
    ptr_coefMatrix_train->row = row;
    ptr_coefMatrix_train->col = col;
    ptr_coefMatrix_train->data= (double*)malloc(sizeof(double)*row*col);
    
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
 	fscanf( fileInput, "%lf", &temp );
    //    printf("num:%lf\n", temp);
        ptr_coefMatrix_train->data[i] = temp;
        i++;
   }
    fclose( fileInput );
    
    //read coefMatrix_cv
    fileInput = fopen("./examples/coefMatrix_cv","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_coefMatrix_cv->row = row;
    ptr_coefMatrix_cv->col = col;
   // ptr_coefMatrix_cv->data= (double*)malloc(sizeof(double)*row*col);
    ptr_coefMatrix_cv->data= (double*)malloc(sizeof(double)*row*col);
    //printf("row:%d col:%d\n", row, col);    
   
    i = 0;

    temp_size = row*col;
    while(i < temp_size) {
 	fscanf( fileInput, "%lf", &temp );
    //    printf("num:%lf\n", temp);
        ptr_coefMatrix_cv->data[i] = temp;
        i++;
   }

    fclose( fileInput );
    
    //read in coefMatrix_test
    fileInput = fopen("./examples/coefMatrix_test","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_coefMatrix_test->row = row;
    ptr_coefMatrix_test->col = col;
    ptr_coefMatrix_test->data= (double*)malloc(sizeof(double)*row*col);
    //ptr_coefMatrix_test->data= (double*)malloc(sizeof(double)*row*col);
    //printf("row:%d col:%d\n", row, col); 
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
 	fscanf( fileInput, "%lf", &temp );
    //    printf("num:%lf\n", temp);
        ptr_coefMatrix_test->data[i] = temp;
        i++;
   }

    fclose( fileInput );
 
 
    fileInput = fopen("./examples1000/examples_train","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_train->row = row;
    ptr_examples_train->col = col;
    ptr_examples_train->data= (double*)malloc(sizeof(double)*row*col);
    //ptr_examples_train->data= (double*)malloc(sizeof(double)*tempsize);
    //printf("row:%d col:%d\n", row, col);
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
        fscanf( fileInput, "%lf", &temp );
    //    printf("num:%lf\n", temp);
        ptr_examples_train->data[i] = temp;
        i++;
   }

    fclose( fileInput );
 
    fileInput = fopen("./examples/examples_cv","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_cv->row = row;
    ptr_examples_cv->col = col;
    ptr_examples_cv->data= (double*)malloc(sizeof(double)*row*col);
    //ptr_examples_cv->data= (double*)malloc(sizeof(double)*tempsize);
    //printf("row:%d col:%d\n", row, col);
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
        fscanf( fileInput, "%lf", &temp );
        //printf("num%d:%lf\n",i, temp);
        ptr_examples_cv->data[i] = temp;
        i++;
   }

    fclose( fileInput );

    fileInput = fopen("./examples/examples_test","r");
    if ( fileInput == NULL ){
        printf( "Unable to open the file!\n" );
	return (0);
    }

    fscanf(fileInput, "%d %d", &row, &col);
    ptr_examples_test->row = row;
    ptr_examples_test->col = col;
    ptr_examples_test->data= (double*)malloc(sizeof(double)*row*col);
    //ptr_examples_test->data= (double*)malloc(sizeof(double)*tempsize);
    //printf("row:%d col:%d\n", row, col);
    i = 0;
    temp_size = row*col;
    while(i < temp_size) {
        fscanf( fileInput, "%lf", &temp );
    //    printf("num:%lf\n", temp);
        ptr_examples_test->data[i] = temp;
        i++;
   }
    printf("Examples successfully read in!\n");
    fclose( fileInput );
    return (1);
}
/***************************************************
    Description: padOne() add a row where all entries are
  1 to the top of a matrix A. Return a MATRIX struct
    NOTE : malloc() is called here,to allocate space for the 
  new matrix.
           The returned matrix is allocated and NOT freed.
****************************************************/
MATRIX padOne(MATRIX A){
    MATRIX returnMatrix;
    int i,j,mallocSize;
    int err;

    returnMatrix.col = A.col;
    returnMatrix.row = A.row + 1;
    mallocSize = returnMatrix.col * returnMatrix.row;
    //returnMatrix.data= (double*)malloc(sizeof(double)*returnMatrix.col*returnMatrix.row);
    returnMatrix.data = (double*)malloc(sizeof(double)*mallocSize);

    for( i=0; i<A.col; i++){
        returnMatrix.data[i*returnMatrix.row] = 1; //pad 1 here
    }
    for( i=1; i<returnMatrix.row; i++)
        for( j=0; j<returnMatrix.col; j++){
	    returnMatrix.data[j*returnMatrix.row+i]=A.data[j*A.row+i-1];
	    //Copies main part of A.Potentially slow!!!
	}
    return returnMatrix;	   
}
/***************************************************************
 * the remove_top_row removes the top row of a matrix. A pointer to this matrix    is passed to the function.Principally, this function is only used in trimming the delta in backpropogation.
 ***************************************************************/

void remove_top_row(MATRIX* ptr_delta){
    
    int mallocSize; 
    double* tempArray, *temp;
    int i, j, k1, k2;
    mallocSize = (ptr_delta->row - 1) * ptr_delta->col;
    tempArray = (double*)malloc(sizeof(double)* mallocSize );
    int k = 0;
    for( j=0; j<ptr_delta->col; j++)	
        for( i=1; i<ptr_delta->row; i++){
           k1 = j * ptr_delta->row + i;
	   k2 = j * (ptr_delta->row-1) + i - 1;
	   tempArray[k2] = ptr_delta->data[k1];
    } 
    temp = ptr_delta->data;
    ptr_delta->data = tempArray;
    free(temp);
    ptr_delta->row -= 1;
}
/**************************************************
 *     Description: costFunction computes the value of the cost function,
 *   as well as the gradient. The return value will be the value and the
 *   argument grad will store the gradient, which is unrolled according to 
 *   the "Theta(:)" in matlab.
 *     NOTE : This function will NOT malloc for grad !
 *     ****************************************************/
double costFunction ( double* grad,
                      double* nn_params,
                      const int input_layer_size,
                      const int hidden_layer_size,
                      const int num_labels,
                      const int NUM_HIDDEN_LAYERS,
                      const MATRIX X,
                      const MATRIX Y,
                      const double lambda){
    double J = 0;       // The value of the cost function will be stored in J.
    MATRIX* Theta, *Theta_grad;   // Theta will be a MATRIX array storing all nn_parameter   
    int currentProg = 0;
    int i = 0;
    int k = 0, index;
    int j = 0;
    int jStart, jEnd;
    int m;
    int ii,jj;
    int mallocSize;
    int err;
    MATRIX *a, *delta;
    MATRIX d_temp, d_Theta, d_a, temp;
    double correction;
    Theta      = ( MATRIX* )malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS+1) );
    Theta_grad = ( MATRIX* )malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS+1) );
    
    Theta[0].data = & nn_params[0];
    Theta[0].row  = hidden_layer_size;
    Theta[0].col  = input_layer_size + 1;
    
    Theta_grad[0].data = & grad[0];
    Theta_grad[0].row  = hidden_layer_size;
    Theta_grad[0].col  = input_layer_size + 1;

    currentProg   = hidden_layer_size * (input_layer_size + 1) - 1; 
    // currentProg is the max index of current Theta.

    for ( i = 1; i <= NUM_HIDDEN_LAYERS-1; i++ ){
        Theta[i].data = & nn_params[currentProg+1];
	Theta[i].row  = hidden_layer_size;
 	Theta[i].col  = hidden_layer_size + 1;
        
	Theta_grad[i].data = & grad[currentProg+1];
	Theta_grad[i].row  = hidden_layer_size;
 	Theta_grad[i].col  = hidden_layer_size + 1;
       
        currentProg  += hidden_layer_size * (hidden_layer_size + 1);
    } 
    Theta[NUM_HIDDEN_LAYERS].data = & nn_params[currentProg+1];
    Theta[NUM_HIDDEN_LAYERS].row  = num_labels;
    Theta[NUM_HIDDEN_LAYERS].col  = hidden_layer_size + 1;

    Theta_grad[NUM_HIDDEN_LAYERS].data = & grad[currentProg+1];
    Theta_grad[NUM_HIDDEN_LAYERS].row  = num_labels;
    Theta_grad[NUM_HIDDEN_LAYERS].col  = hidden_layer_size + 1;


    m = X.col;
    
    /* a=[ones(1,m)];
       z=a;
       for kk=2:NUM_HIDDEN_LAYERS+1
          z{kk}=Theta{kk-1}*a{kk-1};
	  a{kk}=tanh(z{kk});
	  a{kk}=[ones(1,m);a{kk}];
   	end
    */
    a = (MATRIX*)malloc( sizeof(MATRIX)* (NUM_HIDDEN_LAYERS + 2) );
    
    a[0] = padOne( X );
    
    for( i=1; i<=NUM_HIDDEN_LAYERS; i++){
        temp.row = Theta[i-1].row;
	temp.col = a[i-1].col;
	mallocSize = temp.row*temp.col;
	temp.data = (double*)malloc(sizeof(double)*mallocSize);
	
        my_dgemm(  Theta[i-1],
                   a[i-1], 
		   temp , 
		   1.0, 
		   0.0,
		   CblasNoTrans,
		   CblasNoTrans);
	
        for( ii=0; ii<temp.row*temp.col; ii++){
	    temp.data[ii] = tanh( temp.data[ii] );
	}
	a[i] = padOne( temp );


        free(temp.data);
     }

    a[NUM_HIDDEN_LAYERS+1].row = Theta[NUM_HIDDEN_LAYERS].row;
    a[NUM_HIDDEN_LAYERS+1].col = a[NUM_HIDDEN_LAYERS].col; 
    mallocSize = a[NUM_HIDDEN_LAYERS+1].row*a[NUM_HIDDEN_LAYERS+1].col;
    a[NUM_HIDDEN_LAYERS+1].data = (double*) malloc(sizeof(double)*mallocSize),
    my_dgemm( Theta[NUM_HIDDEN_LAYERS], 
              a[NUM_HIDDEN_LAYERS], 
              a[NUM_HIDDEN_LAYERS+1], 
              1.0, 0.0,
	      CblasNoTrans,
	      CblasNoTrans);
    //my_sum ( Y , a[NUM_HIDDEN_LAYERS+1], diff, -1.0 );
    for (i=0; i<Y.col*Y.row; i++){
       J+=(a[NUM_HIDDEN_LAYERS+1].data[i] - Y.data[i])
          *(a[NUM_HIDDEN_LAYERS+1].data[i] - Y.data[i]);
    }
    J /= 2;
    
    //regularization
    correction = 0;
    for( i=0; i<NUM_HIDDEN_LAYERS+1; i++ ){
        jStart = Theta[i].row;
	jEnd   = Theta[i].col * Theta[i].row;
	for ( j=jStart; j<jEnd; j++){
            correction += Theta[i].data[j]*Theta[i].data[j];  	   
	}
    }
    correction *= lambda/2;
    J += correction;
    delta = (MATRIX*)malloc( sizeof(MATRIX)*(NUM_HIDDEN_LAYERS + 2) );   
    
    //delta{end}=output-Y;
    //delta[NUM_HIDDEN_LAYERS+1].data = (double*) malloc 
    //                                          (sizeof(double)*Y.row*Y.col);
    delta[NUM_HIDDEN_LAYERS+1].data = (double*)malloc(sizeof(double)*Y.row*Y.col );

    for( i=0; i<Y.col*Y.row; i++){
        delta[NUM_HIDDEN_LAYERS+1].data[i]= 
	    a[NUM_HIDDEN_LAYERS+1].data[i]-Y.data[i];
    }
    delta[NUM_HIDDEN_LAYERS+1].row = Y.row; 
    delta[NUM_HIDDEN_LAYERS+1].col = Y.col;
    
    my_dgemm( delta[NUM_HIDDEN_LAYERS+1], 
                  a[NUM_HIDDEN_LAYERS],
		  Theta_grad[NUM_HIDDEN_LAYERS],
		  1.0,
		  0.0,
		  CblasNoTrans,
		  CblasTrans);
    for( i=1; i<=NUM_HIDDEN_LAYERS; i++ ){
        k = NUM_HIDDEN_LAYERS - i;
	delta[k+1].col = delta[k+2].col;
	delta[k+1].row = Theta[k+1].col;
        mallocSize = delta[k+1].col * delta[k+1].row;
        delta[k+1].data = (double*) malloc(sizeof(double)*mallocSize );  
	my_dgemm( Theta[k+1],
	          delta[k+2],
		  delta[k+1],
		  1.0,
		  0.0,
		  CblasTrans,
		  CblasNoTrans );
 	for( ii=0; ii<mallocSize; ii++){
	    delta[k+1].data[ii] = delta[k+1].data[ii] * 
	    (1 - a[k+1].data[ii]*a[k+1].data[ii]); //tanh'
	}
        
	remove_top_row(&delta[k+1]);
	
	my_dgemm( delta[k+1],
	          a[k],
		  Theta_grad[k],
		  1.0,
		  0.0,
		  CblasNoTrans,
		  CblasTrans );
        // regularization term.              
        //printf("Before regularization: %lf\n", Theta_grad[k].data[1]);
	for( jj=1; jj<Theta[k].col; jj++)	
            for( ii=0; ii<Theta[k].row; ii++){
                index = ii + jj*Theta[k].row;	         
                Theta_grad[k].data[index] += lambda * Theta[k].data[index];
            }  
         
    } 
     
    // free  everything    
    for( i=0; i<NUM_HIDDEN_LAYERS+2; i++){
        free(a[i].data);
    } 
    for( i=1; i<NUM_HIDDEN_LAYERS+2; i++){
        free(delta[i].data);
    }
    free(Theta);
    free(Theta_grad);
    free(delta);
    free(a);
    return J;
}


double innerProduct (double* v1,double* v2, int length){
    int i;
    double result = 0;
    for( i=0; i<length; i++){
        result += v1[i]*v2[i];
    }
    return result;
}


//v1=alpha * v2
void vectorAssignment (double *v1, double *v2, int length, double alpha){
    int i;

    for( i=0; i<length; i++){
        v1[i] = alpha * v2[i];
    }

    return ;
}

double my_min(double x, double y){
    if ( x>y ){ return y;}
    else { return x;}

}
double my_max(double x, double y){
    if ( x>y ){ return x; } 
    else { return y; }
}
/*******************************************************
 * The fmincg() minimizes the costFunction(),the nn_params will be finally 
 * modified. Return the ultimate value of the costFunction.
 **********************************************************/

double fmincg (       double* nn_params,
                      double (*cost)(double*,double*),
                      const int maxIter,
		      const int nn_paramsLength){
    int length = maxIter;
    
    double RHO   = 0.01,
           SIG   = 0.5,
	   INT   = 0.1,
	   EXT   = 3.0,
	   MAX   = 20.0,
           RATIO = 100.0,
           red   = 1.0;
    
    int        i = 0,
       ls_failed = 0;
    
    double *df0, *df1, *df2, *df3, f0, f1, f2, f3;
    double *s;
    double *nn_params0;
    double *tmp;
    double d1, d2, d3;
    double z1, z2, z3;
    double M , limit, A, B;
    int    ii, jj, kk, success;
    double alpha;
    double returnValue;
    df0        = (double*) malloc(sizeof(double)*nn_paramsLength);
    
    df1        = (double*) malloc(sizeof(double)*nn_paramsLength);

    df2        = (double*) malloc(sizeof(double)*nn_paramsLength);

    df3        = (double*) malloc(sizeof(double)*nn_paramsLength);

    s          = (double*) malloc(sizeof(double)*nn_paramsLength);
  
    nn_params0 = (double*) malloc(sizeof(double)*nn_paramsLength);

    tmp        = (double*) malloc(sizeof(double)*nn_paramsLength);
    /*
    f1  = costFunction (  df1,
                          nn_params,
                          input_layer_size,
                          hidden_layer_size,
                          num_labels,
                          NUM_HIDDEN_LAYERS,
                          X,
                          Y,
                          lambda); 
    */
    f1 = (*cost) (nn_params, df1);
    //s=-df1;
    vectorAssignment( s , df1 , nn_paramsLength , -1.0 );
    /*for( i=0; i<nn_paramsLength; i++){
        s[i] = -df1[i]; 
    }
    */
    //d1=-s'*s;
    d1 = - innerProduct( s, s, nn_paramsLength);
    
    z1 = red/(1-d1);
    
    while( i < length ){
        i += ( length>0 );       
        
	//nn_params0=nn_params; 
	//f0=f1; 
	//df0=df1
	//nn_params += z1*s 
	f0 = f1;
	vectorAssignment( nn_params0, nn_params, nn_paramsLength, 1.0 );
	vectorAssignment(    df0    ,    df1   , nn_paramsLength, 1.0 );
 	for( ii=0; ii<nn_paramsLength; ii++){
	   nn_params[ii] = nn_params[ii] + z1*s[ii];
	}
	/*
	for( ii=0; ii<nn_paramsLength; ii++){
	    nn_params0[ii] = nn_params[ii];
	    df0[ii] = df1[ii];
	    nn_params[ii] = z1 * s[ii];
	}
	*/
         f2 = (*cost) ( nn_params , df2 );
	 i += (length<0);
         d2 = innerProduct( df2 , s , nn_paramsLength );
         
	 f3 = f1; d3 = d1; z3 = -z1;
         
	 if (length > 0){
	     M = MAX;
	 }else{
	     M = my_min( MAX , (double) (-length - i) );
	 }

         success = 0;
	 limit = -1.0;

	 while (1){
             while(  ( (f2>f1+z1*RHO*d1) || (d2>-SIG*d1) ) && (M>0)  ){
	         
		 limit = z1;
		 if (f2 > f1){
		     z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);
		 }else{
                     A = 6*(f2-f3)/z3 + 3*(d2+d3) ;
		     B = 3*(f3-f2) - z3*(d3+2*d2);
		     z2= (sqrt(B*B - A*d2*z3*z3)-B)/A;
		 }
	         
		 z2 = my_max( my_min( z2 , INT*z3 ) , (1-INT)*z3 );
	         z1 = z1 + z2;
	     
	         for( ii=0; ii<nn_paramsLength; ii++){
	             nn_params[ii] = nn_params[ii] + z2*s[ii];
	         }
	         
		 f2 = (*cost) ( nn_params , df2 );
		 M --;
		 i += ( length<0 );
		 d2 = innerProduct( df2 , s , nn_paramsLength );
                 z3 = z3 - z2;
	     
	     }	 
             
	     if( f2 > f1+z1*RHO*d1 || d2 > -SIG*d1 ){
	         break;
	     }
	     else if( d2 > SIG*d1 ){
	         success = 1;
		 break;
	     }
	     else if( M==0 ){
	         break;
	     } 

	     A = 6*(f2-f3)/z3 + 3*(d2+d3);
	     B = 3*(f3-f2) - z3*(d3+2*d2);
	     
	     if( B*B-A*d2*z3*z3 >= 0 ){
	         z2 = -d2*z3*z3/( B + sqrt( B*B-A*d2*z3*z3) );
	     }else{
	         z2 = -d2*z3*z3/( B + sqrt(-B*B+A*d2*z3*z3) );
	     }

	     if( B*B-A*d2*z3*z3 < 0 || z2<0 ){
	         if( limit < -0.5 ){
	             z2 = z1 * (EXT-1) ;
	         }
	         else{
	             z2 = ( limit-z1 )/2 ;
	         }
	     }
             else if( limit > -0.5 && z2+z1 > limit ){
	         z2 = (limit-z1)/2;
	     }
             else if( limit < -0.5 && z2+z1 > z1*EXT){
	         z2 = z1*(EXT-1.0);
	     }
	     else if(z2 < -z3*INT){
	         z2 = -z3 * INT;
	     }
	     else if( limit > -0.5 && z2 < (limit-z1)*(1.0-INT) ){
	         z2 = (limit-z1)*(1.0-INT);
	     }

	     f3 = f2; d3 = d2 ; z3 = -z2;
	     z1 = z1 + z2; 
             for( ii=0; ii<nn_paramsLength; ii++){
	         nn_params[ii] = nn_params[ii] + z2*s[ii];
	     }
             
	     f2 = (*cost) ( nn_params , df2 );
             M --;
	     i += (length<0);
	     d2 = innerProduct( df2, s , nn_paramsLength );

	 }

	 if(success){
	     f1 = f2;
             returnValue = f1;	     //fX = [fX' f1]'
	     //printf("%d | Cost: %lf\r", i , f1 );
	     alpha = (  innerProduct( df2 , df2 , nn_paramsLength) 
	               -innerProduct( df1 , df2 , nn_paramsLength)  )
	             /
		     innerProduct( df1 , df1 , nn_paramsLength );
             
	     for( ii=0 ; ii<nn_paramsLength ; ii++){
	         s[ii] = alpha * s[ii] - df2[ii];
	     }
             
             
	     vectorAssignment( tmp , df1 , nn_paramsLength , 1.0 );
	 
	     vectorAssignment( df1 , df2 , nn_paramsLength , 1.0 );
	     
	     vectorAssignment( df2 , tmp , nn_paramsLength , 1.0 );

	     d2 = innerProduct( df1 , s , nn_paramsLength);

	     if (d2>0){
	         vectorAssignment( s , df1 , nn_paramsLength , -1.0 );
		 d2 = -innerProduct ( s , s , nn_paramsLength );
	     }
	     z1 *= my_min( RATIO , d1/d2 );
	     d1  = d2;
	     ls_failed = 0;   
	 }else{
	     vectorAssignment( nn_params , nn_params0 , nn_paramsLength , 1 );
	     f1 = f0;
	     vectorAssignment(    df1    ,     df0    , nn_paramsLength , 1 );
         if( ls_failed || i>abs(length) ){
	     break;
	 }
         vectorAssignment( tmp , df1 , nn_paramsLength , 1.0 );
	
	 vectorAssignment( df1 , df2 , nn_paramsLength , 1.0 );
	     
	 vectorAssignment( df2 , tmp , nn_paramsLength , 1.0 );

         vectorAssignment(  s  , df1 , nn_paramsLength ,-1.0 );    

         d1 = -innerProduct ( s , s ,  nn_paramsLength);
	 z1 = 1/(1-d1);
	 ls_failed = 1;
    
	 }
    }
    printf( "J = %lf\n",returnValue);
    return returnValue;   
}

